{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# problem3,a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the AUC on the training set is: 0.996767346939\n",
      "the classification error rate of training is: 0.004285714285714286\n",
      "the wrong prediction number in training set is: 3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def featuresRead(filename):\n",
    "    fr = open(filename)\n",
    "    arrayLines = fr.readlines()         #get the number of lines in the file\n",
    "    numberLines = len(arrayLines)\n",
    "    returnMat = zeros((numberLines,3))        #prepare matrix to return\n",
    "    index = 0\n",
    "    for line in arrayLines:\n",
    "        line = line.strip()\n",
    "        listFromLine = line.split(' ')\n",
    "        returnMat[index,:] = listFromLine[0:3]\n",
    "        index += 1\n",
    "    return returnMat\n",
    "\n",
    "def labelsRead(filename):\n",
    "    fr = open(filename)\n",
    "    arrayLines = fr.readlines()         #get the number of lines in the file\n",
    "    numberLines = len(arrayLines)\n",
    "    returnMat = zeros((numberLines,1))        #prepare matrix to return\n",
    "    index = 0\n",
    "    for line in arrayLines:\n",
    "        line = line.strip()\n",
    "        listFromLine = line.split(' ')\n",
    "        returnMat[index,:] = listFromLine[0:1]\n",
    "        index += 1\n",
    "    return returnMat\n",
    "\n",
    "#load the train feature and train lables\n",
    "Xtrain = featuresRead('train-features.txt')\n",
    "ytrain = labelsRead('train-labels.txt')\n",
    "Xtest = featuresRead('test-features.txt')\n",
    "ytest = labelsRead('test-labels.txt')\n",
    "\n",
    "X_message = int(max(Xtrain[:,0]))\n",
    "X_word_id = int(max(Xtrain[:,1]))\n",
    "X_line = Xtrain.shape[0]\n",
    "\n",
    "Xtest_message = int(max(Xtest[:,0]))\n",
    "Xtest_word_id = int(max(Xtest[:,1]))\n",
    "Xtest_line = Xtest.shape[0]\n",
    "\n",
    "i=0\n",
    "wordgood = np.zeros( X_word_id )\n",
    "wordbad = np.zeros( X_word_id )\n",
    "for i in range(X_line): # every line of Xtrain\n",
    "    j=int(Xtrain[i][0])-1\n",
    "    k=int(Xtrain[i][1])-1\n",
    "    if(ytrain[j][0]==0):\n",
    "        wordgood[k] = wordgood[k] + int(Xtrain[i][2])\n",
    "    else:\n",
    "        wordbad[k] = wordbad[k] + int(Xtrain[i][2])\n",
    "\n",
    "Pwordgood = np.zeros( X_word_id )\n",
    "Pwordbad = np.zeros( X_word_id )\n",
    "k=0\n",
    "\n",
    "#sum_word=Xtrain.sum(axis=0)[2]\n",
    "sum_wordgood =sum(wordgood)\n",
    "sum_wordbad =sum(wordbad)\n",
    "for k in range(X_word_id):\n",
    "    Pwordgood[k]=log((wordgood[k]+0.01)/(sum_wordgood+X_word_id))\n",
    "    Pwordbad[k]=log((wordbad[k]+0.01)/(sum_wordbad+X_word_id))\n",
    "\n",
    "Pbad = log(sum(ytrain)/ len(ytrain)) \n",
    "Pgood =log(1- Pbad)   \n",
    "\n",
    "from sklearn import metrics\n",
    "import math\n",
    "y_pred=[]\n",
    "Py_pred=[]\n",
    "i=0\n",
    "j=1\n",
    "y_predgood = Pgood\n",
    "y_predbad = Pbad\n",
    "for i in range(X_line):   #X_line\n",
    "\n",
    "    if(Xtrain[i][0]==j):\n",
    "        word=int(Xtrain[i][1])-1\n",
    "        y_predgood = y_predgood + Pwordgood[word]*Xtrain[i][2]\n",
    "        y_predbad = y_predbad + Pwordbad[word]*Xtrain[i][2]\n",
    "    else:\n",
    "        j=j+1\n",
    "\n",
    "        if(y_predgood>y_predbad):\n",
    "            y_pred.append([0])\n",
    "        else:\n",
    "            y_pred.append([1])\n",
    "        \n",
    "        Py_pred.append(y_predgood/(y_predgood+y_predbad))    \n",
    "        y_predgood = Pgood\n",
    "        y_predbad = Pbad\n",
    "# add the last ypred    \n",
    "if(y_predgood>y_predbad):\n",
    "    y_pred.append([0])\n",
    "else:\n",
    "    y_pred.append([1])\n",
    "Py_pred.append((y_predgood-y_predbad)/(y_predgood+y_predbad))\n",
    "\n",
    "#compute the AUC\n",
    "fpr, tpr, thresholds = metrics.roc_curve(ytrain[:,0], Py_pred)\n",
    "AUCtrain = metrics.auc(fpr, tpr)\n",
    "print('the AUC on the training set is:',AUCtrain)\n",
    "\n",
    "#compute the classification error\n",
    "i=0\n",
    "class_error = 0\n",
    "for i in range(X_message):\n",
    "    if(ytrain[i][0]!=y_pred[i][0]):\n",
    "        class_error=class_error+1\n",
    "Pclass_error = class_error/X_message\n",
    "print('the classification error rate of training is:',Pclass_error)\n",
    "print('the wrong prediction number in training set is:',class_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3 b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the AUC on the test set is: 0.998520710059\n",
      "the classification error rate of test is: 0.015384615384615385\n",
      "the wrong prediction number in test set is: 4\n"
     ]
    }
   ],
   "source": [
    "ytest_pred=[]\n",
    "Pytest_pred=[]\n",
    "i=0\n",
    "j=1\n",
    "ytest_predgood = Pgood\n",
    "ytest_predbad = Pbad\n",
    "for i in range(Xtest_line):\n",
    "    \n",
    "    if(Xtest[i][0]==j):\n",
    "        word=int(Xtest[i][1])-1\n",
    "        ytest_predgood = ytest_predgood+ Pwordgood[word]*Xtest[i][2]\n",
    "        ytest_predbad = ytest_predbad+ Pwordbad[word]*Xtest[i][2]\n",
    "    else:\n",
    "        j=j+1\n",
    "        \n",
    "        if(ytest_predgood > ytest_predbad):\n",
    "            ytest_pred.append([0])\n",
    "        else:\n",
    "            ytest_pred.append([1])\n",
    "        Pytest_pred.append(ytest_predgood/(ytest_predgood+ytest_predbad))     \n",
    "        ytest_predgood = Pgood\n",
    "        ytest_predbad = Pbad\n",
    "\n",
    "# add the last ypred    \n",
    "if(ytest_predgood>ytest_predbad):\n",
    "    ytest_pred.append([0])\n",
    "else:\n",
    "    ytest_pred.append([1])\n",
    "Pytest_pred.append(ytest_predgood/(ytest_predgood+ytest_predbad)) \n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(ytest[:,0], Pytest_pred)\n",
    "AUCtrain_test = metrics.auc(fpr, tpr)\n",
    "print('the AUC on the test set is:',AUCtrain_test)\n",
    "\n",
    "i=0\n",
    "class_error_test = 0\n",
    "for i in range(Xtest_message):\n",
    "    if(ytest[i][0]!=ytest_pred[i][0]):\n",
    "        class_error_test=class_error_test+1\n",
    "Pclass_error_test = class_error_test/Xtest_message\n",
    "print('the classification error rate of test is:',Pclass_error_test)\n",
    "print('the wrong prediction number in test set is:',class_error_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
